{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "id": "kDdDaGnWH2Yv"
   },
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "nMm5UxMNJvr7",
    "outputId": "f5842998-3f3a-4e9a-9a0b-b58f4fb9af55"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "  <div id=\"df-1e2b2986-a4fb-4cc6-acce-14d372555938\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input Current (A)</th>\n",
       "      <th>Error Rate (Defects)</th>\n",
       "      <th>Calibration Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.832088</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.822885</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.743443</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.753390</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.961214</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e2b2986-a4fb-4cc6-acce-14d372555938')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "\n",
       "\n",
       "\n",
       "    <div id=\"df-7cc12771-c6fc-43f3-a781-5087b263a781\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7cc12771-c6fc-43f3-a781-5087b263a781')\"\n",
       "              title=\"Suggest charts.\"\n",
       "              style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "    </div>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "    background-color: #E8F0FE;\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: #1967D2;\n",
       "    height: 32px;\n",
       "    padding: 0 0 0 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: #E2EBFA;\n",
       "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: #174EA6;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "    background-color: #3B4455;\n",
       "    fill: #D2E3FC;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart:hover {\n",
       "    background-color: #434B5C;\n",
       "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "    fill: #FFFFFF;\n",
       "  }\n",
       "</style>\n",
       "\n",
       "    <script>\n",
       "      async function quickchart(key) {\n",
       "        const containerElement = document.querySelector('#' + key);\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      }\n",
       "    </script>\n",
       "\n",
       "      <script>\n",
       "\n",
       "function displayQuickchartButton(domScope) {\n",
       "  let quickchartButtonEl =\n",
       "    domScope.querySelector('#df-7cc12771-c6fc-43f3-a781-5087b263a781 button.colab-df-quickchart');\n",
       "  quickchartButtonEl.style.display =\n",
       "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "}\n",
       "\n",
       "        displayQuickchartButton(document);\n",
       "      </script>\n",
       "      <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-1e2b2986-a4fb-4cc6-acce-14d372555938 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-1e2b2986-a4fb-4cc6-acce-14d372555938');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   Input Current (A)  Error Rate (Defects)  Calibration Data\n",
       "0               0.00              0.832088                 0\n",
       "1               0.01              0.822885                 0\n",
       "2               0.02              0.743443                 0\n",
       "3               0.03              0.753390                 0\n",
       "4               0.04              0.961214                 0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the data\n",
    "data = pd.read_excel('/content/Dataset.xlsx')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "s2Q_GjzePxGf",
    "outputId": "54c0599a-a739-4cee-e71d-3bcb7479cd97"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "  <div id=\"df-fba730ea-359f-418b-a8e3-9947812882af\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input Current (A)</th>\n",
       "      <th>Error Rate (Defects)</th>\n",
       "      <th>Calibration Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.832088</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.822885</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.743443</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.753390</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.961214</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fba730ea-359f-418b-a8e3-9947812882af')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "\n",
       "\n",
       "\n",
       "    <div id=\"df-2ebfa2f4-9607-47a2-b977-ea8d7feda550\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2ebfa2f4-9607-47a2-b977-ea8d7feda550')\"\n",
       "              title=\"Suggest charts.\"\n",
       "              style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "    </div>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "    background-color: #E8F0FE;\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: #1967D2;\n",
       "    height: 32px;\n",
       "    padding: 0 0 0 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: #E2EBFA;\n",
       "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: #174EA6;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "    background-color: #3B4455;\n",
       "    fill: #D2E3FC;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart:hover {\n",
       "    background-color: #434B5C;\n",
       "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "    fill: #FFFFFF;\n",
       "  }\n",
       "</style>\n",
       "\n",
       "    <script>\n",
       "      async function quickchart(key) {\n",
       "        const containerElement = document.querySelector('#' + key);\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      }\n",
       "    </script>\n",
       "\n",
       "      <script>\n",
       "\n",
       "function displayQuickchartButton(domScope) {\n",
       "  let quickchartButtonEl =\n",
       "    domScope.querySelector('#df-2ebfa2f4-9607-47a2-b977-ea8d7feda550 button.colab-df-quickchart');\n",
       "  quickchartButtonEl.style.display =\n",
       "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "}\n",
       "\n",
       "        displayQuickchartButton(document);\n",
       "      </script>\n",
       "      <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-fba730ea-359f-418b-a8e3-9947812882af button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-fba730ea-359f-418b-a8e3-9947812882af');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   Input Current (A)  Error Rate (Defects)  Calibration Data\n",
       "0               0.00              0.832088                -1\n",
       "1               0.01              0.822885                -1\n",
       "2               0.02              0.743443                -1\n",
       "3               0.03              0.753390                -1\n",
       "4               0.04              0.961214                -1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting labels from [0, 1] -> [-1, 1]\n",
    "data['Calibration Data'] = data['Calibration Data'].apply(lambda x: -1 if x == 0 else 1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "id": "Pxb71xY7J1YI"
   },
   "outputs": [],
   "source": [
    "# Creating class for SVM\n",
    "class SVM():\n",
    "    def __init__(self):\n",
    "        self.W = None\n",
    "        self.B = None\n",
    "        self.C = 1.0\n",
    "        self.alpha = 0.001 # Learning Rate\n",
    "\n",
    "    def hinge_loss(self, y_true, y_pred):\n",
    "        reg = 0.5 * np.linalg.norm(self.W)\n",
    "        return reg + self.C * max(0, 1 - (y_pred*y_true))\n",
    "\n",
    "def __get_loss(self, X, y):\n",
    "    loss = 0\n",
    "    for i in range(X.shape[0]):\n",
    "        y_pred = np.dot(self.W, X[i]) + self.B\n",
    "        loss += self.hinge_loss(y[i], y_pred)\n",
    "    return loss\n",
    "\n",
    "  def gradient_descent():\n",
    "    pass\n",
    "\n",
    "  def fit(self, X, y, batch_size=20, epochs=100):\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    n_samples, n_features = X.shape\n",
    "\n",
    "    self.W = np.random.randn(n_features)\n",
    "    self.B = 0\n",
    "\n",
    "    indexes = np.arange(n_samples)\n",
    "    np.random.shuffle(indexes)\n",
    "\n",
    "    if len(X[0]) != 2:\n",
    "        print(\"Expected 2 features...\")\n",
    "        return\n",
    "\n",
    "    loss = []\n",
    "\n",
    "    # Iterate epoch\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        rand_index = np.random.randint(0, n_samples)\n",
    "        y_pred = np.dot(self.W, X[rand_index]) + self.B\n",
    "\n",
    "        l = self.__get_loss(X, y) / n_samples\n",
    "        loss.append(l)\n",
    "\n",
    "        print(f\"Epoch: {epoch+1} Loss: {l:.4f}\")\n",
    "\n",
    "      # Iterate over each sample\n",
    "        for batch in range(0, n_samples, batch_size):\n",
    "        gradw = 0\n",
    "        gradb = 0\n",
    "\n",
    "        for j in range(batch, batch+batch_size):\n",
    "            if j < X.shape[0]:\n",
    "                i = indexes[j]\n",
    "                y_pred = y[i] * (np.dot(self.W, X[i].T) + self.B)\n",
    "\n",
    "            if y_pred > 0:\n",
    "                gradw += 0\n",
    "                gradb += 0\n",
    "            else:\n",
    "                gradw += self.C * y[i] * X[i]\n",
    "                gradb += self.C * y[i]\n",
    "\n",
    "        # Update the weight and bias based on gradients\n",
    "        self.W = self.W - self.alpha * self.W + self.alpha * gradw\n",
    "        self.B = self.B + self.alpha * gradb\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j-wLYLxMO_KR",
    "outputId": "9d2dec95-3877-4dce-a2fc-fff7f8943799",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss: 1.2509\n",
      "Epoch: 2 Loss: 1.2692\n",
      "Epoch: 3 Loss: 1.2884\n",
      "Epoch: 4 Loss: 1.3078\n",
      "Epoch: 5 Loss: 1.3260\n",
      "Epoch: 6 Loss: 1.3391\n",
      "Epoch: 7 Loss: 1.3466\n",
      "Epoch: 8 Loss: 1.3519\n",
      "Epoch: 9 Loss: 1.3557\n",
      "Epoch: 10 Loss: 1.3561\n",
      "Epoch: 11 Loss: 1.3559\n",
      "Epoch: 12 Loss: 1.3543\n",
      "Epoch: 13 Loss: 1.3521\n",
      "Epoch: 14 Loss: 1.3490\n",
      "Epoch: 15 Loss: 1.3450\n",
      "Epoch: 16 Loss: 1.3410\n",
      "Epoch: 17 Loss: 1.3371\n",
      "Epoch: 18 Loss: 1.3340\n",
      "Epoch: 19 Loss: 1.3301\n",
      "Epoch: 20 Loss: 1.3262\n",
      "Epoch: 21 Loss: 1.3224\n",
      "Epoch: 22 Loss: 1.3192\n",
      "Epoch: 23 Loss: 1.3154\n",
      "Epoch: 24 Loss: 1.3123\n",
      "Epoch: 25 Loss: 1.3085\n",
      "Epoch: 26 Loss: 1.3047\n",
      "Epoch: 27 Loss: 1.3016\n",
      "Epoch: 28 Loss: 1.2979\n",
      "Epoch: 29 Loss: 1.2939\n",
      "Epoch: 30 Loss: 1.2906\n",
      "Epoch: 31 Loss: 1.2873\n",
      "Epoch: 32 Loss: 1.2834\n",
      "Epoch: 33 Loss: 1.2801\n",
      "Epoch: 34 Loss: 1.2768\n",
      "Epoch: 35 Loss: 1.2735\n",
      "Epoch: 36 Loss: 1.2702\n",
      "Epoch: 37 Loss: 1.2669\n",
      "Epoch: 38 Loss: 1.2637\n",
      "Epoch: 39 Loss: 1.2604\n",
      "Epoch: 40 Loss: 1.2572\n",
      "Epoch: 41 Loss: 1.2540\n",
      "Epoch: 42 Loss: 1.2508\n",
      "Epoch: 43 Loss: 1.2476\n",
      "Epoch: 44 Loss: 1.2444\n",
      "Epoch: 45 Loss: 1.2412\n",
      "Epoch: 46 Loss: 1.2381\n",
      "Epoch: 47 Loss: 1.2350\n",
      "Epoch: 48 Loss: 1.2318\n",
      "Epoch: 49 Loss: 1.2287\n",
      "Epoch: 50 Loss: 1.2256\n",
      "Epoch: 51 Loss: 1.2225\n",
      "Epoch: 52 Loss: 1.2201\n",
      "Epoch: 53 Loss: 1.2166\n",
      "Epoch: 54 Loss: 1.2131\n",
      "Epoch: 55 Loss: 1.2096\n",
      "Epoch: 56 Loss: 1.2073\n",
      "Epoch: 57 Loss: 1.2038\n",
      "Epoch: 58 Loss: 1.2003\n",
      "Epoch: 59 Loss: 1.1978\n",
      "Epoch: 60 Loss: 1.1944\n",
      "Epoch: 61 Loss: 1.1910\n",
      "Epoch: 62 Loss: 1.1885\n",
      "Epoch: 63 Loss: 1.1851\n",
      "Epoch: 64 Loss: 1.1827\n",
      "Epoch: 65 Loss: 1.1793\n",
      "Epoch: 66 Loss: 1.1760\n",
      "Epoch: 67 Loss: 1.1736\n",
      "Epoch: 68 Loss: 1.1703\n",
      "Epoch: 69 Loss: 1.1679\n",
      "Epoch: 70 Loss: 1.1646\n",
      "Epoch: 71 Loss: 1.1613\n",
      "Epoch: 72 Loss: 1.1590\n",
      "Epoch: 73 Loss: 1.1558\n",
      "Epoch: 74 Loss: 1.1535\n",
      "Epoch: 75 Loss: 1.1502\n",
      "Epoch: 76 Loss: 1.1480\n",
      "Epoch: 77 Loss: 1.1448\n",
      "Epoch: 78 Loss: 1.1416\n",
      "Epoch: 79 Loss: 1.1394\n",
      "Epoch: 80 Loss: 1.1362\n",
      "Epoch: 81 Loss: 1.1340\n",
      "Epoch: 82 Loss: 1.1309\n",
      "Epoch: 83 Loss: 1.1287\n",
      "Epoch: 84 Loss: 1.1256\n",
      "Epoch: 85 Loss: 1.1211\n",
      "Epoch: 86 Loss: 1.1206\n",
      "Epoch: 87 Loss: 1.1169\n",
      "Epoch: 88 Loss: 1.1148\n",
      "Epoch: 89 Loss: 1.1101\n",
      "Epoch: 90 Loss: 1.1073\n",
      "Epoch: 91 Loss: 1.1046\n",
      "Epoch: 92 Loss: 1.1028\n",
      "Epoch: 93 Loss: 1.1007\n",
      "Epoch: 94 Loss: 1.0969\n",
      "Epoch: 95 Loss: 1.0942\n",
      "Epoch: 96 Loss: 1.0923\n",
      "Epoch: 97 Loss: 1.0884\n",
      "Epoch: 98 Loss: 1.0871\n",
      "Epoch: 99 Loss: 1.0833\n",
      "Epoch: 100 Loss: 1.0805\n",
      "Epoch: 101 Loss: 1.0785\n",
      "Epoch: 102 Loss: 1.0772\n",
      "Epoch: 103 Loss: 1.0731\n",
      "Epoch: 104 Loss: 1.0711\n",
      "Epoch: 105 Loss: 1.0684\n",
      "Epoch: 106 Loss: 1.0664\n",
      "Epoch: 107 Loss: 1.0638\n",
      "Epoch: 108 Loss: 1.0611\n",
      "Epoch: 109 Loss: 1.0594\n",
      "Epoch: 110 Loss: 1.0576\n",
      "Epoch: 111 Loss: 1.0549\n",
      "Epoch: 112 Loss: 1.0529\n",
      "Epoch: 113 Loss: 1.0509\n",
      "Epoch: 114 Loss: 1.0489\n",
      "Epoch: 115 Loss: 1.0470\n",
      "Epoch: 116 Loss: 1.0441\n",
      "Epoch: 117 Loss: 1.0421\n",
      "Epoch: 118 Loss: 1.0402\n",
      "Epoch: 119 Loss: 1.0383\n",
      "Epoch: 120 Loss: 1.0364\n",
      "Epoch: 121 Loss: 1.0340\n",
      "Epoch: 122 Loss: 1.0321\n",
      "Epoch: 123 Loss: 1.0302\n",
      "Epoch: 124 Loss: 1.0276\n",
      "Epoch: 125 Loss: 1.0266\n",
      "Epoch: 126 Loss: 1.0243\n",
      "Epoch: 127 Loss: 1.0224\n",
      "Epoch: 128 Loss: 1.0199\n",
      "Epoch: 129 Loss: 1.0182\n",
      "Epoch: 130 Loss: 1.0165\n",
      "Epoch: 131 Loss: 1.0148\n",
      "Epoch: 132 Loss: 1.0131\n",
      "Epoch: 133 Loss: 1.0116\n",
      "Epoch: 134 Loss: 1.0090\n",
      "Epoch: 135 Loss: 1.0083\n",
      "Epoch: 136 Loss: 1.0057\n",
      "Epoch: 137 Loss: 1.0053\n",
      "Epoch: 138 Loss: 1.0022\n",
      "Epoch: 139 Loss: 1.0097\n",
      "Epoch: 140 Loss: 1.0012\n",
      "Epoch: 141 Loss: 1.0088\n",
      "Epoch: 142 Loss: 1.0013\n",
      "Epoch: 143 Loss: 0.9983\n",
      "Epoch: 144 Loss: 1.0064\n",
      "Epoch: 145 Loss: 0.9986\n",
      "Epoch: 146 Loss: 1.0031\n",
      "Epoch: 147 Loss: 0.9973\n",
      "Epoch: 148 Loss: 1.0053\n",
      "Epoch: 149 Loss: 0.9969\n",
      "Epoch: 150 Loss: 1.0045\n",
      "Epoch: 151 Loss: 0.9967\n",
      "Epoch: 152 Loss: 1.0040\n",
      "Epoch: 153 Loss: 0.9964\n",
      "Epoch: 154 Loss: 1.0035\n",
      "Epoch: 155 Loss: 0.9962\n",
      "Epoch: 156 Loss: 1.0027\n",
      "Epoch: 157 Loss: 0.9962\n",
      "Epoch: 158 Loss: 1.0025\n",
      "Epoch: 159 Loss: 0.9961\n",
      "Epoch: 160 Loss: 1.0022\n",
      "Epoch: 161 Loss: 0.9960\n",
      "Epoch: 162 Loss: 1.0021\n",
      "Epoch: 163 Loss: 0.9959\n",
      "Epoch: 164 Loss: 1.0019\n",
      "Epoch: 165 Loss: 0.9959\n",
      "Epoch: 166 Loss: 1.0018\n",
      "Epoch: 167 Loss: 0.9959\n",
      "Epoch: 168 Loss: 1.0017\n",
      "Epoch: 169 Loss: 0.9958\n",
      "Epoch: 170 Loss: 1.0016\n",
      "Epoch: 171 Loss: 0.9958\n",
      "Epoch: 172 Loss: 1.0016\n",
      "Epoch: 173 Loss: 0.9958\n",
      "Epoch: 174 Loss: 1.0016\n",
      "Epoch: 175 Loss: 0.9958\n",
      "Epoch: 176 Loss: 1.0016\n",
      "Epoch: 177 Loss: 0.9958\n",
      "Epoch: 178 Loss: 1.0017\n",
      "Epoch: 179 Loss: 0.9959\n",
      "Epoch: 180 Loss: 1.0017\n",
      "Epoch: 181 Loss: 0.9954\n",
      "Epoch: 182 Loss: 1.0018\n",
      "Epoch: 183 Loss: 1.0011\n",
      "Epoch: 184 Loss: 0.9958\n",
      "Epoch: 185 Loss: 1.0016\n",
      "Epoch: 186 Loss: 0.9959\n",
      "Epoch: 187 Loss: 1.0017\n",
      "Epoch: 188 Loss: 0.9954\n",
      "Epoch: 189 Loss: 1.0017\n",
      "Epoch: 190 Loss: 0.9984\n",
      "Epoch: 191 Loss: 1.0020\n",
      "Epoch: 192 Loss: 0.9958\n",
      "Epoch: 193 Loss: 1.0020\n",
      "Epoch: 194 Loss: 0.9959\n",
      "Epoch: 195 Loss: 1.0001\n",
      "Epoch: 196 Loss: 1.0002\n",
      "Epoch: 197 Loss: 0.9988\n",
      "Epoch: 198 Loss: 1.0025\n",
      "Epoch: 199 Loss: 0.9967\n",
      "Epoch: 200 Loss: 1.0024\n",
      "Epoch: 201 Loss: 0.9967\n",
      "Epoch: 202 Loss: 1.0005\n",
      "Epoch: 203 Loss: 0.9962\n",
      "Epoch: 204 Loss: 1.0020\n",
      "Epoch: 205 Loss: 0.9962\n",
      "Epoch: 206 Loss: 1.0020\n",
      "Epoch: 207 Loss: 0.9963\n",
      "Epoch: 208 Loss: 1.0021\n",
      "Epoch: 209 Loss: 0.9958\n",
      "Epoch: 210 Loss: 1.0021\n",
      "Epoch: 211 Loss: 0.9945\n",
      "Epoch: 212 Loss: 1.0012\n",
      "Epoch: 213 Loss: 1.0002\n",
      "Epoch: 214 Loss: 0.9955\n",
      "Epoch: 215 Loss: 0.9992\n",
      "Epoch: 216 Loss: 1.0028\n",
      "Epoch: 217 Loss: 1.0017\n",
      "Epoch: 218 Loss: 0.9959\n",
      "Epoch: 219 Loss: 1.0011\n",
      "Epoch: 220 Loss: 0.9953\n",
      "Epoch: 221 Loss: 1.0016\n",
      "Epoch: 222 Loss: 0.9958\n",
      "Epoch: 223 Loss: 1.0016\n",
      "Epoch: 224 Loss: 0.9958\n",
      "Epoch: 225 Loss: 1.0016\n",
      "Epoch: 226 Loss: 0.9954\n",
      "Epoch: 227 Loss: 1.0017\n",
      "Epoch: 228 Loss: 0.9984\n",
      "Epoch: 229 Loss: 1.0020\n",
      "Epoch: 230 Loss: 0.9963\n",
      "Epoch: 231 Loss: 1.0020\n",
      "Epoch: 232 Loss: 0.9953\n",
      "Epoch: 233 Loss: 1.0016\n",
      "Epoch: 234 Loss: 0.9958\n",
      "Epoch: 235 Loss: 1.0016\n",
      "Epoch: 236 Loss: 0.9959\n",
      "Epoch: 237 Loss: 1.0017\n",
      "Epoch: 238 Loss: 0.9954\n",
      "Epoch: 239 Loss: 1.0017\n",
      "Epoch: 240 Loss: 1.0015\n",
      "Epoch: 241 Loss: 0.9958\n",
      "Epoch: 242 Loss: 1.0020\n",
      "Epoch: 243 Loss: 0.9989\n",
      "Epoch: 244 Loss: 1.0025\n",
      "Epoch: 245 Loss: 0.9958\n",
      "Epoch: 246 Loss: 1.0021\n",
      "Epoch: 247 Loss: 0.9963\n",
      "Epoch: 248 Loss: 1.0020\n",
      "Epoch: 249 Loss: 0.9963\n",
      "Epoch: 250 Loss: 1.0020\n",
      "Epoch: 251 Loss: 0.9958\n",
      "Epoch: 252 Loss: 1.0020\n",
      "Epoch: 253 Loss: 0.9953\n",
      "Epoch: 254 Loss: 1.0016\n",
      "Epoch: 255 Loss: 0.9958\n",
      "Epoch: 256 Loss: 1.0016\n",
      "Epoch: 257 Loss: 0.9959\n",
      "Epoch: 258 Loss: 1.0017\n",
      "Epoch: 259 Loss: 0.9954\n",
      "Epoch: 260 Loss: 1.0017\n",
      "Epoch: 261 Loss: 1.0015\n",
      "Epoch: 262 Loss: 0.9958\n",
      "Epoch: 263 Loss: 1.0020\n",
      "Epoch: 264 Loss: 0.9988\n",
      "Epoch: 265 Loss: 1.0025\n",
      "Epoch: 266 Loss: 0.9958\n",
      "Epoch: 267 Loss: 1.0021\n",
      "Epoch: 268 Loss: 0.9963\n",
      "Epoch: 269 Loss: 1.0020\n",
      "Epoch: 270 Loss: 0.9963\n",
      "Epoch: 271 Loss: 1.0020\n",
      "Epoch: 272 Loss: 0.9958\n",
      "Epoch: 273 Loss: 1.0020\n",
      "Epoch: 274 Loss: 0.9953\n",
      "Epoch: 275 Loss: 1.0016\n",
      "Epoch: 276 Loss: 0.9958\n",
      "Epoch: 277 Loss: 1.0016\n",
      "Epoch: 278 Loss: 0.9959\n",
      "Epoch: 279 Loss: 1.0017\n",
      "Epoch: 280 Loss: 0.9954\n",
      "Epoch: 281 Loss: 1.0017\n",
      "Epoch: 282 Loss: 1.0015\n",
      "Epoch: 283 Loss: 0.9958\n",
      "Epoch: 284 Loss: 1.0020\n",
      "Epoch: 285 Loss: 0.9988\n",
      "Epoch: 286 Loss: 1.0025\n",
      "Epoch: 287 Loss: 0.9958\n",
      "Epoch: 288 Loss: 1.0021\n",
      "Epoch: 289 Loss: 0.9963\n",
      "Epoch: 290 Loss: 1.0020\n",
      "Epoch: 291 Loss: 0.9963\n",
      "Epoch: 292 Loss: 1.0020\n",
      "Epoch: 293 Loss: 0.9958\n",
      "Epoch: 294 Loss: 1.0020\n",
      "Epoch: 295 Loss: 0.9953\n",
      "Epoch: 296 Loss: 1.0016\n",
      "Epoch: 297 Loss: 0.9958\n",
      "Epoch: 298 Loss: 1.0016\n",
      "Epoch: 299 Loss: 0.9959\n",
      "Epoch: 300 Loss: 1.0017\n",
      "Epoch: 301 Loss: 0.9954\n",
      "Epoch: 302 Loss: 1.0017\n",
      "Epoch: 303 Loss: 1.0015\n",
      "Epoch: 304 Loss: 0.9958\n",
      "Epoch: 305 Loss: 1.0020\n",
      "Epoch: 306 Loss: 0.9988\n",
      "Epoch: 307 Loss: 1.0025\n",
      "Epoch: 308 Loss: 0.9958\n",
      "Epoch: 309 Loss: 1.0021\n",
      "Epoch: 310 Loss: 0.9962\n",
      "Epoch: 311 Loss: 1.0020\n",
      "Epoch: 312 Loss: 0.9963\n",
      "Epoch: 313 Loss: 1.0020\n",
      "Epoch: 314 Loss: 0.9958\n",
      "Epoch: 315 Loss: 1.0020\n",
      "Epoch: 316 Loss: 0.9989\n",
      "Epoch: 317 Loss: 1.0025\n",
      "Epoch: 318 Loss: 0.9958\n",
      "Epoch: 319 Loss: 1.0021\n",
      "Epoch: 320 Loss: 0.9963\n",
      "Epoch: 321 Loss: 1.0020\n",
      "Epoch: 322 Loss: 0.9963\n",
      "Epoch: 323 Loss: 1.0020\n",
      "Epoch: 324 Loss: 0.9963\n",
      "Epoch: 325 Loss: 1.0020\n",
      "Epoch: 326 Loss: 0.9953\n",
      "Epoch: 327 Loss: 1.0016\n",
      "Epoch: 328 Loss: 0.9958\n",
      "Epoch: 329 Loss: 1.0016\n",
      "Epoch: 330 Loss: 0.9959\n",
      "Epoch: 331 Loss: 1.0017\n",
      "Epoch: 332 Loss: 0.9954\n",
      "Epoch: 333 Loss: 1.0017\n",
      "Epoch: 334 Loss: 1.0015\n",
      "Epoch: 335 Loss: 0.9958\n",
      "Epoch: 336 Loss: 1.0020\n",
      "Epoch: 337 Loss: 0.9988\n",
      "Epoch: 338 Loss: 1.0025\n",
      "Epoch: 339 Loss: 0.9963\n",
      "Epoch: 340 Loss: 1.0021\n",
      "Epoch: 341 Loss: 0.9963\n",
      "Epoch: 342 Loss: 1.0020\n",
      "Epoch: 343 Loss: 0.9963\n",
      "Epoch: 344 Loss: 1.0020\n",
      "Epoch: 345 Loss: 0.9958\n",
      "Epoch: 346 Loss: 1.0020\n",
      "Epoch: 347 Loss: 0.9953\n",
      "Epoch: 348 Loss: 1.0016\n",
      "Epoch: 349 Loss: 0.9958\n",
      "Epoch: 350 Loss: 1.0016\n",
      "Epoch: 351 Loss: 0.9959\n",
      "Epoch: 352 Loss: 1.0017\n",
      "Epoch: 353 Loss: 0.9954\n",
      "Epoch: 354 Loss: 1.0017\n",
      "Epoch: 355 Loss: 1.0015\n",
      "Epoch: 356 Loss: 0.9958\n",
      "Epoch: 357 Loss: 1.0021\n",
      "Epoch: 358 Loss: 0.9950\n",
      "Epoch: 359 Loss: 0.9988\n",
      "Epoch: 360 Loss: 1.0024\n",
      "Epoch: 361 Loss: 0.9962\n",
      "Epoch: 362 Loss: 1.0024\n",
      "Epoch: 363 Loss: 0.9993\n",
      "Epoch: 364 Loss: 1.0029\n",
      "Epoch: 365 Loss: 0.9972\n",
      "Epoch: 366 Loss: 1.0020\n",
      "Epoch: 367 Loss: 0.9977\n",
      "Epoch: 368 Loss: 1.0021\n",
      "Epoch: 369 Loss: 0.9963\n",
      "Epoch: 370 Loss: 1.0020\n",
      "Epoch: 371 Loss: 0.9958\n",
      "Epoch: 372 Loss: 1.0020\n",
      "Epoch: 373 Loss: 0.9954\n",
      "Epoch: 374 Loss: 1.0016\n",
      "Epoch: 375 Loss: 0.9958\n",
      "Epoch: 376 Loss: 1.0016\n",
      "Epoch: 377 Loss: 0.9959\n",
      "Epoch: 378 Loss: 1.0016\n",
      "Epoch: 379 Loss: 0.9958\n",
      "Epoch: 380 Loss: 1.0017\n",
      "Epoch: 381 Loss: 0.9959\n",
      "Epoch: 382 Loss: 1.0017\n",
      "Epoch: 383 Loss: 1.0013\n",
      "Epoch: 384 Loss: 0.9955\n",
      "Epoch: 385 Loss: 0.9993\n",
      "Epoch: 386 Loss: 1.0024\n",
      "Epoch: 387 Loss: 0.9967\n",
      "Epoch: 388 Loss: 1.0010\n",
      "Epoch: 389 Loss: 1.0006\n",
      "Epoch: 390 Loss: 1.0008\n",
      "Epoch: 391 Loss: 0.9950\n",
      "Epoch: 392 Loss: 0.9988\n",
      "Epoch: 393 Loss: 1.0024\n",
      "Epoch: 394 Loss: 0.9967\n",
      "Epoch: 395 Loss: 1.0024\n",
      "Epoch: 396 Loss: 0.9962\n",
      "Epoch: 397 Loss: 1.0024\n",
      "Epoch: 398 Loss: 0.9992\n",
      "Epoch: 399 Loss: 1.0029\n",
      "Epoch: 400 Loss: 0.9972\n",
      "Epoch: 401 Loss: 1.0019\n",
      "Epoch: 402 Loss: 0.9977\n",
      "Epoch: 403 Loss: 1.0015\n",
      "Epoch: 404 Loss: 0.9949\n",
      "Epoch: 405 Loss: 1.0017\n",
      "Epoch: 406 Loss: 0.9949\n",
      "Epoch: 407 Loss: 1.0012\n",
      "Epoch: 408 Loss: 0.9954\n",
      "Epoch: 409 Loss: 1.0002\n",
      "Epoch: 410 Loss: 0.9988\n",
      "Epoch: 411 Loss: 1.0025\n",
      "Epoch: 412 Loss: 0.9973\n",
      "Epoch: 413 Loss: 1.0013\n",
      "Epoch: 414 Loss: 0.9954\n",
      "Epoch: 415 Loss: 1.0012\n",
      "Epoch: 416 Loss: 0.9954\n",
      "Epoch: 417 Loss: 1.0016\n",
      "Epoch: 418 Loss: 0.9949\n",
      "Epoch: 419 Loss: 1.0012\n",
      "Epoch: 420 Loss: 0.9954\n",
      "Epoch: 421 Loss: 1.0002\n",
      "Epoch: 422 Loss: 0.9988\n",
      "Epoch: 423 Loss: 1.0025\n",
      "Epoch: 424 Loss: 0.9993\n",
      "Epoch: 425 Loss: 1.0025\n",
      "Epoch: 426 Loss: 0.9967\n",
      "Epoch: 427 Loss: 1.0024\n",
      "Epoch: 428 Loss: 0.9966\n",
      "Epoch: 429 Loss: 1.0024\n",
      "Epoch: 430 Loss: 0.9967\n",
      "Epoch: 431 Loss: 1.0024\n",
      "Epoch: 432 Loss: 0.9962\n",
      "Epoch: 433 Loss: 1.0024\n",
      "Epoch: 434 Loss: 0.9993\n",
      "Epoch: 435 Loss: 1.0029\n",
      "Epoch: 436 Loss: 0.9972\n",
      "Epoch: 437 Loss: 1.0020\n",
      "Epoch: 438 Loss: 0.9977\n",
      "Epoch: 439 Loss: 1.0015\n",
      "Epoch: 440 Loss: 0.9955\n",
      "Epoch: 441 Loss: 0.9992\n",
      "Epoch: 442 Loss: 1.0028\n",
      "Epoch: 443 Loss: 0.9971\n",
      "Epoch: 444 Loss: 1.0024\n",
      "Epoch: 445 Loss: 0.9966\n",
      "Epoch: 446 Loss: 1.0029\n",
      "Epoch: 447 Loss: 1.0033\n",
      "Epoch: 448 Loss: 1.0018\n",
      "Epoch: 449 Loss: 0.9959\n",
      "Epoch: 450 Loss: 1.0017\n",
      "Epoch: 451 Loss: 0.9958\n",
      "Epoch: 452 Loss: 1.0016\n",
      "Epoch: 453 Loss: 0.9958\n",
      "Epoch: 454 Loss: 1.0016\n",
      "Epoch: 455 Loss: 0.9958\n",
      "Epoch: 456 Loss: 1.0016\n",
      "Epoch: 457 Loss: 0.9958\n",
      "Epoch: 458 Loss: 1.0016\n",
      "Epoch: 459 Loss: 0.9959\n",
      "Epoch: 460 Loss: 1.0016\n",
      "Epoch: 461 Loss: 0.9959\n",
      "Epoch: 462 Loss: 1.0017\n",
      "Epoch: 463 Loss: 0.9954\n",
      "Epoch: 464 Loss: 1.0018\n",
      "Epoch: 465 Loss: 0.9984\n",
      "Epoch: 466 Loss: 1.0020\n",
      "Epoch: 467 Loss: 0.9953\n",
      "Epoch: 468 Loss: 1.0020\n",
      "Epoch: 469 Loss: 0.9955\n",
      "Epoch: 470 Loss: 0.9993\n",
      "Epoch: 471 Loss: 1.0015\n",
      "Epoch: 472 Loss: 0.9958\n",
      "Epoch: 473 Loss: 1.0020\n",
      "Epoch: 474 Loss: 0.9989\n",
      "Epoch: 475 Loss: 1.0025\n",
      "Epoch: 476 Loss: 0.9958\n",
      "Epoch: 477 Loss: 1.0021\n",
      "Epoch: 478 Loss: 0.9963\n",
      "Epoch: 479 Loss: 1.0020\n",
      "Epoch: 480 Loss: 0.9963\n",
      "Epoch: 481 Loss: 1.0020\n",
      "Epoch: 482 Loss: 0.9963\n",
      "Epoch: 483 Loss: 1.0020\n",
      "Epoch: 484 Loss: 0.9953\n",
      "Epoch: 485 Loss: 1.0020\n",
      "Epoch: 486 Loss: 0.9960\n",
      "Epoch: 487 Loss: 0.9998\n",
      "Epoch: 488 Loss: 0.9984\n",
      "Epoch: 489 Loss: 1.0021\n",
      "Epoch: 490 Loss: 0.9963\n",
      "Epoch: 491 Loss: 1.0020\n",
      "Epoch: 492 Loss: 0.9963\n",
      "Epoch: 493 Loss: 1.0020\n",
      "Epoch: 494 Loss: 0.9958\n",
      "Epoch: 495 Loss: 1.0020\n",
      "Epoch: 496 Loss: 0.9968\n",
      "Epoch: 497 Loss: 0.9997\n",
      "Epoch: 498 Loss: 1.0028\n",
      "Epoch: 499 Loss: 0.9971\n",
      "Epoch: 500 Loss: 1.0024\n",
      "Epoch: 501 Loss: 0.9966\n",
      "Epoch: 502 Loss: 1.0029\n",
      "Epoch: 503 Loss: 1.0033\n",
      "Epoch: 504 Loss: 1.0018\n",
      "Epoch: 505 Loss: 0.9959\n",
      "Epoch: 506 Loss: 1.0017\n",
      "Epoch: 507 Loss: 0.9958\n",
      "Epoch: 508 Loss: 1.0016\n",
      "Epoch: 509 Loss: 0.9958\n",
      "Epoch: 510 Loss: 1.0016\n",
      "Epoch: 511 Loss: 0.9958\n",
      "Epoch: 512 Loss: 1.0016\n",
      "Epoch: 513 Loss: 0.9958\n",
      "Epoch: 514 Loss: 1.0016\n",
      "Epoch: 515 Loss: 0.9959\n",
      "Epoch: 516 Loss: 1.0016\n",
      "Epoch: 517 Loss: 0.9959\n",
      "Epoch: 518 Loss: 1.0022\n",
      "Epoch: 519 Loss: 1.0020\n",
      "Epoch: 520 Loss: 0.9962\n",
      "Epoch: 521 Loss: 1.0025\n",
      "Epoch: 522 Loss: 1.0002\n",
      "Epoch: 523 Loss: 0.9989\n",
      "Epoch: 524 Loss: 1.0026\n",
      "Epoch: 525 Loss: 0.9967\n",
      "Epoch: 526 Loss: 1.0025\n",
      "Epoch: 527 Loss: 0.9967\n",
      "Epoch: 528 Loss: 1.0025\n",
      "Epoch: 529 Loss: 0.9958\n",
      "Epoch: 530 Loss: 1.0020\n",
      "Epoch: 531 Loss: 0.9962\n",
      "Epoch: 532 Loss: 1.0020\n",
      "Epoch: 533 Loss: 0.9963\n",
      "Epoch: 534 Loss: 1.0020\n",
      "Epoch: 535 Loss: 0.9958\n",
      "Epoch: 536 Loss: 1.0020\n",
      "Epoch: 537 Loss: 0.9950\n",
      "Epoch: 538 Loss: 0.9988\n",
      "Epoch: 539 Loss: 1.0024\n",
      "Epoch: 540 Loss: 0.9962\n",
      "Epoch: 541 Loss: 1.0024\n",
      "Epoch: 542 Loss: 0.9993\n",
      "Epoch: 543 Loss: 1.0029\n",
      "Epoch: 544 Loss: 0.9972\n",
      "Epoch: 545 Loss: 1.0020\n",
      "Epoch: 546 Loss: 0.9976\n",
      "Epoch: 547 Loss: 1.0025\n",
      "Epoch: 548 Loss: 0.9967\n",
      "Epoch: 549 Loss: 1.0025\n",
      "Epoch: 550 Loss: 0.9958\n",
      "Epoch: 551 Loss: 1.0020\n",
      "Epoch: 552 Loss: 0.9962\n",
      "Epoch: 553 Loss: 1.0020\n",
      "Epoch: 554 Loss: 0.9963\n",
      "Epoch: 555 Loss: 1.0020\n",
      "Epoch: 556 Loss: 0.9958\n",
      "Epoch: 557 Loss: 1.0020\n",
      "Epoch: 558 Loss: 0.9988\n",
      "Epoch: 559 Loss: 1.0025\n",
      "Epoch: 560 Loss: 0.9963\n",
      "Epoch: 561 Loss: 1.0021\n",
      "Epoch: 562 Loss: 0.9963\n",
      "Epoch: 563 Loss: 1.0020\n",
      "Epoch: 564 Loss: 0.9963\n",
      "Epoch: 565 Loss: 1.0020\n",
      "Epoch: 566 Loss: 0.9953\n",
      "Epoch: 567 Loss: 1.0016\n",
      "Epoch: 568 Loss: 0.9958\n",
      "Epoch: 569 Loss: 1.0016\n",
      "Epoch: 570 Loss: 0.9958\n",
      "Epoch: 571 Loss: 1.0017\n",
      "Epoch: 572 Loss: 0.9954\n",
      "Epoch: 573 Loss: 1.0017\n",
      "Epoch: 574 Loss: 0.9984\n",
      "Epoch: 575 Loss: 1.0020\n",
      "Epoch: 576 Loss: 0.9953\n",
      "Epoch: 577 Loss: 1.0016\n",
      "Epoch: 578 Loss: 0.9958\n",
      "Epoch: 579 Loss: 1.0016\n",
      "Epoch: 580 Loss: 0.9958\n",
      "Epoch: 581 Loss: 1.0016\n",
      "Epoch: 582 Loss: 0.9959\n",
      "Epoch: 583 Loss: 1.0016\n",
      "Epoch: 584 Loss: 0.9959\n",
      "Epoch: 585 Loss: 1.0022\n",
      "Epoch: 586 Loss: 1.0020\n",
      "Epoch: 587 Loss: 0.9962\n",
      "Epoch: 588 Loss: 1.0024\n",
      "Epoch: 589 Loss: 1.0010\n",
      "Epoch: 590 Loss: 0.9951\n",
      "Epoch: 591 Loss: 0.9988\n",
      "Epoch: 592 Loss: 1.0025\n",
      "Epoch: 593 Loss: 0.9962\n",
      "Epoch: 594 Loss: 1.0025\n",
      "Epoch: 595 Loss: 0.9958\n",
      "Epoch: 596 Loss: 1.0020\n",
      "Epoch: 597 Loss: 0.9962\n",
      "Epoch: 598 Loss: 1.0020\n",
      "Epoch: 599 Loss: 0.9963\n",
      "Epoch: 600 Loss: 1.0020\n",
      "Epoch: 601 Loss: 0.9958\n",
      "Epoch: 602 Loss: 1.0021\n",
      "Epoch: 603 Loss: 0.9950\n",
      "Epoch: 604 Loss: 0.9988\n",
      "Epoch: 605 Loss: 1.0024\n",
      "Epoch: 606 Loss: 0.9962\n",
      "Epoch: 607 Loss: 1.0024\n",
      "Epoch: 608 Loss: 0.9993\n",
      "Epoch: 609 Loss: 1.0029\n",
      "Epoch: 610 Loss: 0.9972\n",
      "Epoch: 611 Loss: 1.0020\n",
      "Epoch: 612 Loss: 0.9976\n",
      "Epoch: 613 Loss: 1.0025\n",
      "Epoch: 614 Loss: 0.9963\n",
      "Epoch: 615 Loss: 1.0021\n",
      "Epoch: 616 Loss: 0.9963\n",
      "Epoch: 617 Loss: 1.0020\n",
      "Epoch: 618 Loss: 0.9963\n",
      "Epoch: 619 Loss: 1.0020\n",
      "Epoch: 620 Loss: 0.9953\n",
      "Epoch: 621 Loss: 1.0016\n",
      "Epoch: 622 Loss: 0.9958\n",
      "Epoch: 623 Loss: 1.0016\n",
      "Epoch: 624 Loss: 0.9958\n",
      "Epoch: 625 Loss: 1.0016\n",
      "Epoch: 626 Loss: 0.9959\n",
      "Epoch: 627 Loss: 1.0017\n",
      "Epoch: 628 Loss: 0.9964\n",
      "Epoch: 629 Loss: 1.0002\n",
      "Epoch: 630 Loss: 0.9988\n",
      "Epoch: 631 Loss: 1.0024\n",
      "Epoch: 632 Loss: 0.9967\n",
      "Epoch: 633 Loss: 1.0015\n",
      "Epoch: 634 Loss: 0.9977\n",
      "Epoch: 635 Loss: 1.0016\n",
      "Epoch: 636 Loss: 0.9959\n",
      "Epoch: 637 Loss: 1.0016\n",
      "Epoch: 638 Loss: 0.9959\n",
      "Epoch: 639 Loss: 1.0017\n",
      "Epoch: 640 Loss: 0.9954\n",
      "Epoch: 641 Loss: 1.0017\n",
      "Epoch: 642 Loss: 0.9984\n",
      "Epoch: 643 Loss: 1.0020\n",
      "Epoch: 644 Loss: 0.9953\n",
      "Epoch: 645 Loss: 1.0016\n",
      "Epoch: 646 Loss: 0.9958\n",
      "Epoch: 647 Loss: 1.0016\n",
      "Epoch: 648 Loss: 0.9958\n",
      "Epoch: 649 Loss: 1.0016\n",
      "Epoch: 650 Loss: 0.9959\n",
      "Epoch: 651 Loss: 1.0016\n",
      "Epoch: 652 Loss: 0.9959\n",
      "Epoch: 653 Loss: 1.0022\n",
      "Epoch: 654 Loss: 1.0020\n",
      "Epoch: 655 Loss: 0.9962\n",
      "Epoch: 656 Loss: 1.0024\n",
      "Epoch: 657 Loss: 1.0010\n",
      "Epoch: 658 Loss: 0.9951\n",
      "Epoch: 659 Loss: 0.9988\n",
      "Epoch: 660 Loss: 1.0025\n",
      "Epoch: 661 Loss: 0.9967\n",
      "Epoch: 662 Loss: 1.0005\n",
      "Epoch: 663 Loss: 0.9962\n",
      "Epoch: 664 Loss: 1.0020\n",
      "Epoch: 665 Loss: 0.9962\n",
      "Epoch: 666 Loss: 1.0020\n",
      "Epoch: 667 Loss: 0.9963\n",
      "Epoch: 668 Loss: 1.0020\n",
      "Epoch: 669 Loss: 0.9958\n",
      "Epoch: 670 Loss: 1.0021\n",
      "Epoch: 671 Loss: 0.9945\n",
      "Epoch: 672 Loss: 1.0012\n",
      "Epoch: 673 Loss: 1.0002\n",
      "Epoch: 674 Loss: 0.9950\n",
      "Epoch: 675 Loss: 1.0012\n",
      "Epoch: 676 Loss: 0.9954\n",
      "Epoch: 677 Loss: 0.9997\n",
      "Epoch: 678 Loss: 1.0019\n",
      "Epoch: 679 Loss: 0.9962\n",
      "Epoch: 680 Loss: 1.0025\n",
      "Epoch: 681 Loss: 0.9992\n",
      "Epoch: 682 Loss: 1.0029\n",
      "Epoch: 683 Loss: 0.9972\n",
      "Epoch: 684 Loss: 1.0019\n",
      "Epoch: 685 Loss: 0.9959\n",
      "Epoch: 686 Loss: 0.9996\n",
      "Epoch: 687 Loss: 1.0033\n",
      "Epoch: 688 Loss: 1.0001\n",
      "Epoch: 689 Loss: 1.0033\n",
      "Epoch: 690 Loss: 0.9980\n",
      "Epoch: 691 Loss: 1.0033\n",
      "Epoch: 692 Loss: 0.9981\n",
      "Epoch: 693 Loss: 1.0020\n",
      "Epoch: 694 Loss: 0.9962\n",
      "Epoch: 695 Loss: 1.0020\n",
      "Epoch: 696 Loss: 0.9962\n",
      "Epoch: 697 Loss: 1.0020\n",
      "Epoch: 698 Loss: 0.9962\n",
      "Epoch: 699 Loss: 1.0020\n",
      "Epoch: 700 Loss: 0.9963\n",
      "Epoch: 701 Loss: 1.0020\n",
      "Epoch: 702 Loss: 0.9958\n",
      "Epoch: 703 Loss: 1.0021\n",
      "Epoch: 704 Loss: 0.9950\n",
      "Epoch: 705 Loss: 0.9988\n",
      "Epoch: 706 Loss: 1.0024\n",
      "Epoch: 707 Loss: 0.9962\n",
      "Epoch: 708 Loss: 1.0024\n",
      "Epoch: 709 Loss: 0.9992\n",
      "Epoch: 710 Loss: 1.0029\n",
      "Epoch: 711 Loss: 0.9972\n",
      "Epoch: 712 Loss: 1.0019\n",
      "Epoch: 713 Loss: 0.9977\n",
      "Epoch: 714 Loss: 1.0015\n",
      "Epoch: 715 Loss: 0.9949\n",
      "Epoch: 716 Loss: 1.0016\n",
      "Epoch: 717 Loss: 0.9954\n",
      "Epoch: 718 Loss: 1.0016\n",
      "Epoch: 719 Loss: 0.9950\n",
      "Epoch: 720 Loss: 1.0012\n",
      "Epoch: 721 Loss: 0.9954\n",
      "Epoch: 722 Loss: 1.0007\n",
      "Epoch: 723 Loss: 0.9949\n",
      "Epoch: 724 Loss: 1.0016\n",
      "Epoch: 725 Loss: 1.0006\n",
      "Epoch: 726 Loss: 0.9968\n",
      "Epoch: 727 Loss: 0.9997\n",
      "Epoch: 728 Loss: 1.0028\n",
      "Epoch: 729 Loss: 0.9977\n",
      "Epoch: 730 Loss: 1.0021\n",
      "Epoch: 731 Loss: 0.9958\n",
      "Epoch: 732 Loss: 1.0021\n",
      "Epoch: 733 Loss: 0.9954\n",
      "Epoch: 734 Loss: 1.0016\n",
      "Epoch: 735 Loss: 0.9958\n",
      "Epoch: 736 Loss: 1.0016\n",
      "Epoch: 737 Loss: 0.9958\n",
      "Epoch: 738 Loss: 1.0016\n",
      "Epoch: 739 Loss: 0.9958\n",
      "Epoch: 740 Loss: 1.0016\n",
      "Epoch: 741 Loss: 0.9959\n",
      "Epoch: 742 Loss: 1.0017\n",
      "Epoch: 743 Loss: 0.9954\n",
      "Epoch: 744 Loss: 1.0017\n",
      "Epoch: 745 Loss: 1.0016\n",
      "Epoch: 746 Loss: 0.9958\n",
      "Epoch: 747 Loss: 1.0021\n",
      "Epoch: 748 Loss: 1.0006\n",
      "Epoch: 749 Loss: 0.9946\n",
      "Epoch: 750 Loss: 0.9984\n",
      "Epoch: 751 Loss: 1.0020\n",
      "Epoch: 752 Loss: 0.9958\n",
      "Epoch: 753 Loss: 1.0020\n",
      "Epoch: 754 Loss: 0.9953\n",
      "Epoch: 755 Loss: 1.0016\n",
      "Epoch: 756 Loss: 0.9958\n",
      "Epoch: 757 Loss: 1.0016\n",
      "Epoch: 758 Loss: 0.9959\n",
      "Epoch: 759 Loss: 1.0016\n",
      "Epoch: 760 Loss: 0.9954\n",
      "Epoch: 761 Loss: 1.0017\n",
      "Epoch: 762 Loss: 0.9984\n",
      "Epoch: 763 Loss: 1.0020\n",
      "Epoch: 764 Loss: 0.9963\n",
      "Epoch: 765 Loss: 1.0020\n",
      "Epoch: 766 Loss: 0.9963\n",
      "Epoch: 767 Loss: 1.0020\n",
      "Epoch: 768 Loss: 0.9958\n",
      "Epoch: 769 Loss: 1.0021\n",
      "Epoch: 770 Loss: 0.9950\n",
      "Epoch: 771 Loss: 0.9988\n",
      "Epoch: 772 Loss: 1.0024\n",
      "Epoch: 773 Loss: 0.9962\n",
      "Epoch: 774 Loss: 1.0024\n",
      "Epoch: 775 Loss: 0.9993\n",
      "Epoch: 776 Loss: 1.0029\n",
      "Epoch: 777 Loss: 0.9972\n",
      "Epoch: 778 Loss: 1.0020\n",
      "Epoch: 779 Loss: 0.9977\n",
      "Epoch: 780 Loss: 1.0021\n",
      "Epoch: 781 Loss: 0.9963\n",
      "Epoch: 782 Loss: 1.0020\n",
      "Epoch: 783 Loss: 0.9962\n",
      "Epoch: 784 Loss: 1.0020\n",
      "Epoch: 785 Loss: 0.9963\n",
      "Epoch: 786 Loss: 1.0020\n",
      "Epoch: 787 Loss: 0.9953\n",
      "Epoch: 788 Loss: 1.0021\n",
      "Epoch: 789 Loss: 1.0025\n",
      "Epoch: 790 Loss: 0.9967\n",
      "Epoch: 791 Loss: 1.0024\n",
      "Epoch: 792 Loss: 0.9967\n",
      "Epoch: 793 Loss: 1.0005\n",
      "Epoch: 794 Loss: 0.9962\n",
      "Epoch: 795 Loss: 1.0020\n",
      "Epoch: 796 Loss: 0.9962\n",
      "Epoch: 797 Loss: 1.0020\n",
      "Epoch: 798 Loss: 0.9963\n",
      "Epoch: 799 Loss: 1.0021\n",
      "Epoch: 800 Loss: 0.9958\n",
      "Epoch: 801 Loss: 1.0021\n",
      "Epoch: 802 Loss: 0.9955\n",
      "Epoch: 803 Loss: 0.9992\n",
      "Epoch: 804 Loss: 1.0024\n",
      "Epoch: 805 Loss: 0.9967\n",
      "Epoch: 806 Loss: 1.0015\n",
      "Epoch: 807 Loss: 0.9977\n",
      "Epoch: 808 Loss: 1.0016\n",
      "Epoch: 809 Loss: 0.9958\n",
      "Epoch: 810 Loss: 1.0017\n",
      "Epoch: 811 Loss: 0.9954\n",
      "Epoch: 812 Loss: 1.0017\n",
      "Epoch: 813 Loss: 0.9984\n",
      "Epoch: 814 Loss: 1.0020\n",
      "Epoch: 815 Loss: 0.9958\n",
      "Epoch: 816 Loss: 1.0020\n",
      "Epoch: 817 Loss: 0.9953\n",
      "Epoch: 818 Loss: 1.0016\n",
      "Epoch: 819 Loss: 0.9958\n",
      "Epoch: 820 Loss: 1.0016\n",
      "Epoch: 821 Loss: 0.9959\n",
      "Epoch: 822 Loss: 1.0016\n",
      "Epoch: 823 Loss: 0.9959\n",
      "Epoch: 824 Loss: 1.0017\n",
      "Epoch: 825 Loss: 0.9954\n",
      "Epoch: 826 Loss: 1.0017\n",
      "Epoch: 827 Loss: 0.9984\n",
      "Epoch: 828 Loss: 1.0020\n",
      "Epoch: 829 Loss: 0.9958\n",
      "Epoch: 830 Loss: 1.0020\n",
      "Epoch: 831 Loss: 0.9953\n",
      "Epoch: 832 Loss: 1.0016\n",
      "Epoch: 833 Loss: 0.9958\n",
      "Epoch: 834 Loss: 1.0016\n",
      "Epoch: 835 Loss: 0.9959\n",
      "Epoch: 836 Loss: 1.0017\n",
      "Epoch: 837 Loss: 0.9954\n",
      "Epoch: 838 Loss: 1.0017\n",
      "Epoch: 839 Loss: 0.9984\n",
      "Epoch: 840 Loss: 1.0020\n",
      "Epoch: 841 Loss: 0.9958\n",
      "Epoch: 842 Loss: 1.0020\n",
      "Epoch: 843 Loss: 0.9953\n",
      "Epoch: 844 Loss: 1.0016\n",
      "Epoch: 845 Loss: 0.9958\n",
      "Epoch: 846 Loss: 1.0016\n",
      "Epoch: 847 Loss: 0.9959\n",
      "Epoch: 848 Loss: 1.0017\n",
      "Epoch: 849 Loss: 0.9954\n",
      "Epoch: 850 Loss: 1.0017\n",
      "Epoch: 851 Loss: 0.9984\n",
      "Epoch: 852 Loss: 1.0020\n",
      "Epoch: 853 Loss: 0.9958\n",
      "Epoch: 854 Loss: 1.0020\n",
      "Epoch: 855 Loss: 0.9953\n",
      "Epoch: 856 Loss: 1.0016\n",
      "Epoch: 857 Loss: 0.9958\n",
      "Epoch: 858 Loss: 1.0016\n",
      "Epoch: 859 Loss: 0.9958\n",
      "Epoch: 860 Loss: 1.0016\n",
      "Epoch: 861 Loss: 0.9958\n",
      "Epoch: 862 Loss: 1.0017\n",
      "Epoch: 863 Loss: 0.9959\n",
      "Epoch: 864 Loss: 1.0018\n",
      "Epoch: 865 Loss: 0.9954\n",
      "Epoch: 866 Loss: 1.0018\n",
      "Epoch: 867 Loss: 1.0016\n",
      "Epoch: 868 Loss: 0.9958\n",
      "Epoch: 869 Loss: 1.0021\n",
      "Epoch: 870 Loss: 0.9950\n",
      "Epoch: 871 Loss: 0.9988\n",
      "Epoch: 872 Loss: 1.0024\n",
      "Epoch: 873 Loss: 0.9962\n",
      "Epoch: 874 Loss: 1.0024\n",
      "Epoch: 875 Loss: 0.9992\n",
      "Epoch: 876 Loss: 1.0029\n",
      "Epoch: 877 Loss: 0.9972\n",
      "Epoch: 878 Loss: 1.0019\n",
      "Epoch: 879 Loss: 0.9977\n",
      "Epoch: 880 Loss: 1.0015\n",
      "Epoch: 881 Loss: 0.9949\n",
      "Epoch: 882 Loss: 1.0016\n",
      "Epoch: 883 Loss: 0.9954\n",
      "Epoch: 884 Loss: 1.0016\n",
      "Epoch: 885 Loss: 0.9950\n",
      "Epoch: 886 Loss: 1.0012\n",
      "Epoch: 887 Loss: 0.9954\n",
      "Epoch: 888 Loss: 1.0007\n",
      "Epoch: 889 Loss: 0.9949\n",
      "Epoch: 890 Loss: 1.0016\n",
      "Epoch: 891 Loss: 1.0006\n",
      "Epoch: 892 Loss: 0.9968\n",
      "Epoch: 893 Loss: 0.9997\n",
      "Epoch: 894 Loss: 1.0028\n",
      "Epoch: 895 Loss: 0.9977\n",
      "Epoch: 896 Loss: 1.0021\n",
      "Epoch: 897 Loss: 0.9958\n",
      "Epoch: 898 Loss: 1.0021\n",
      "Epoch: 899 Loss: 0.9954\n",
      "Epoch: 900 Loss: 1.0016\n",
      "Epoch: 901 Loss: 0.9958\n",
      "Epoch: 902 Loss: 1.0016\n",
      "Epoch: 903 Loss: 0.9958\n",
      "Epoch: 904 Loss: 1.0016\n",
      "Epoch: 905 Loss: 0.9958\n",
      "Epoch: 906 Loss: 1.0016\n",
      "Epoch: 907 Loss: 0.9959\n",
      "Epoch: 908 Loss: 1.0017\n",
      "Epoch: 909 Loss: 0.9954\n",
      "Epoch: 910 Loss: 1.0018\n",
      "Epoch: 911 Loss: 1.0016\n",
      "Epoch: 912 Loss: 0.9958\n",
      "Epoch: 913 Loss: 1.0021\n",
      "Epoch: 914 Loss: 1.0006\n",
      "Epoch: 915 Loss: 0.9946\n",
      "Epoch: 916 Loss: 0.9984\n",
      "Epoch: 917 Loss: 1.0020\n",
      "Epoch: 918 Loss: 0.9958\n",
      "Epoch: 919 Loss: 1.0020\n",
      "Epoch: 920 Loss: 0.9953\n",
      "Epoch: 921 Loss: 1.0016\n",
      "Epoch: 922 Loss: 0.9958\n",
      "Epoch: 923 Loss: 1.0016\n",
      "Epoch: 924 Loss: 0.9959\n",
      "Epoch: 925 Loss: 1.0016\n",
      "Epoch: 926 Loss: 0.9954\n",
      "Epoch: 927 Loss: 1.0017\n",
      "Epoch: 928 Loss: 0.9984\n",
      "Epoch: 929 Loss: 1.0020\n",
      "Epoch: 930 Loss: 0.9963\n",
      "Epoch: 931 Loss: 1.0020\n",
      "Epoch: 932 Loss: 0.9963\n",
      "Epoch: 933 Loss: 1.0020\n",
      "Epoch: 934 Loss: 0.9958\n",
      "Epoch: 935 Loss: 1.0021\n",
      "Epoch: 936 Loss: 0.9950\n",
      "Epoch: 937 Loss: 0.9988\n",
      "Epoch: 938 Loss: 1.0024\n",
      "Epoch: 939 Loss: 0.9962\n",
      "Epoch: 940 Loss: 1.0024\n",
      "Epoch: 941 Loss: 0.9993\n",
      "Epoch: 942 Loss: 1.0029\n",
      "Epoch: 943 Loss: 0.9972\n",
      "Epoch: 944 Loss: 1.0020\n",
      "Epoch: 945 Loss: 0.9977\n",
      "Epoch: 946 Loss: 1.0021\n",
      "Epoch: 947 Loss: 0.9963\n",
      "Epoch: 948 Loss: 1.0020\n",
      "Epoch: 949 Loss: 0.9962\n",
      "Epoch: 950 Loss: 1.0020\n",
      "Epoch: 951 Loss: 0.9963\n",
      "Epoch: 952 Loss: 1.0020\n",
      "Epoch: 953 Loss: 0.9953\n",
      "Epoch: 954 Loss: 1.0021\n",
      "Epoch: 955 Loss: 1.0025\n",
      "Epoch: 956 Loss: 0.9967\n",
      "Epoch: 957 Loss: 1.0024\n",
      "Epoch: 958 Loss: 0.9967\n",
      "Epoch: 959 Loss: 1.0005\n",
      "Epoch: 960 Loss: 0.9962\n",
      "Epoch: 961 Loss: 1.0020\n",
      "Epoch: 962 Loss: 0.9962\n",
      "Epoch: 963 Loss: 1.0020\n",
      "Epoch: 964 Loss: 0.9963\n",
      "Epoch: 965 Loss: 1.0021\n",
      "Epoch: 966 Loss: 0.9958\n",
      "Epoch: 967 Loss: 1.0021\n",
      "Epoch: 968 Loss: 0.9955\n",
      "Epoch: 969 Loss: 0.9992\n",
      "Epoch: 970 Loss: 1.0024\n",
      "Epoch: 971 Loss: 0.9967\n",
      "Epoch: 972 Loss: 1.0015\n",
      "Epoch: 973 Loss: 0.9977\n",
      "Epoch: 974 Loss: 1.0016\n",
      "Epoch: 975 Loss: 0.9959\n",
      "Epoch: 976 Loss: 1.0017\n",
      "Epoch: 977 Loss: 0.9954\n",
      "Epoch: 978 Loss: 1.0017\n",
      "Epoch: 979 Loss: 0.9984\n",
      "Epoch: 980 Loss: 1.0020\n",
      "Epoch: 981 Loss: 0.9958\n",
      "Epoch: 982 Loss: 1.0020\n",
      "Epoch: 983 Loss: 0.9953\n",
      "Epoch: 984 Loss: 1.0016\n",
      "Epoch: 985 Loss: 0.9958\n",
      "Epoch: 986 Loss: 1.0016\n",
      "Epoch: 987 Loss: 0.9959\n",
      "Epoch: 988 Loss: 1.0016\n",
      "Epoch: 989 Loss: 0.9959\n",
      "Epoch: 990 Loss: 1.0017\n",
      "Epoch: 991 Loss: 0.9954\n",
      "Epoch: 992 Loss: 1.0017\n",
      "Epoch: 993 Loss: 0.9984\n",
      "Epoch: 994 Loss: 1.0020\n",
      "Epoch: 995 Loss: 0.9958\n",
      "Epoch: 996 Loss: 1.0020\n",
      "Epoch: 997 Loss: 0.9959\n",
      "Epoch: 998 Loss: 1.0006\n",
      "Epoch: 999 Loss: 1.0008\n",
      "Epoch: 1000 Loss: 0.9950\n"
     ]
    }
   ],
   "source": [
    "svm_model = SVM()\n",
    "loss = svm_model.fit(\n",
    "    X = data[['Input Current (A)', 'Error Rate (Defects)']],\n",
    "    y = data['Calibration Data'],\n",
    "    # batch_size=20,\n",
    "    epochs=1_000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "id": "E9bfWAz4RBqD"
   },
   "outputs": [],
   "source": [
    "X = np.array(data[['Input Current (A)', 'Error Rate (Defects)']])\n",
    "y = np.array(data['Calibration Data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "yHf7oy2mWMeX",
    "outputId": "276f6468-adb4-43c3-b95d-05a1e11e8925"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing svm\n",
    "xx = np.linspace(X[:, 0].min() - 1, X[:, 0].max() + 1, 100)\n",
    "\n",
    "X_pos = X[y==1]\n",
    "X_neg = X[y==-1]\n",
    "\n",
    "plt.scatter(X_pos[:, 0], X_pos[:, 1], color='blue', label='+ive class')\n",
    "plt.scatter(X_neg[:, 0], X_neg[:, 1], color='red', label='-ive class')\n",
    "\n",
    "yy = -(svm_model.W[0] / svm_model.W[1]) * xx - (svm_model.B/svm_model.W[1])\n",
    "\n",
    "plt.plot(xx, yy, '-')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DzF4kClDrXzg"
   },
   "source": [
    "Since our support vector machine follows a linear path rather than the non-linear distribution of the data shown above, it was unable to fit the points very well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YIa67wxSpgBp"
   },
   "source": [
    "### From Scikit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "id": "8jWRA2bAbH0o"
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "ygR7YjkGppjr",
    "outputId": "73e94774-08fa-4ce2-b891-d8686dfb009d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC()\n",
    "clf.fit(data[['Input Current (A)', 'Error Rate (Defects)']], data['Calibration Data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "stsUgCH_pxgb",
    "outputId": "6589396b-0682-41f0-93fb-7697580a4f8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X)\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1cl295TWp1Cz",
    "outputId": "f26e4556-f453-4076-c656-24fff550635d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[73  0]\n",
      " [28  0]]\n"
     ]
    }
   ],
   "source": [
    "conf_mat = confusion_matrix(y, y_pred)\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EAgM1o_ErgtH"
   },
   "source": [
    "The svm was unable to perform well even in the above scenario because it frequently returns false positive results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ns5qzc-qsPyQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
